{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T21:15:23.707922Z",
     "iopub.status.busy": "2024-12-06T21:15:23.707431Z",
     "iopub.status.idle": "2024-12-06T21:15:24.499569Z",
     "shell.execute_reply": "2024-12-06T21:15:24.498371Z",
     "shell.execute_reply.started": "2024-12-06T21:15:23.707878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from 'e:\\\\College\\\\4- Senior 2\\\\Semester 1\\\\NLP\\\\Project\\\\config.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Add the path to the utils folder\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "import importlib\n",
    "# Custom modules\n",
    "from utils import memory_usage\n",
    "from config import run_config, MODELS_PATH, FEATURES_PATH, PROCESSED_DATA_PATH\n",
    "importlib.reload(sys.modules['utils'])\n",
    "importlib.reload(sys.modules['config'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T21:15:24.510775Z",
     "iopub.status.busy": "2024-12-06T21:15:24.510375Z",
     "iopub.status.idle": "2024-12-06T21:15:24.519935Z",
     "shell.execute_reply": "2024-12-06T21:15:24.518949Z",
     "shell.execute_reply.started": "2024-12-06T21:15:24.510724Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "run_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.utils import io\n",
    "\n",
    "# with io.capture_output() as captured:\n",
    "#     %run ../../1-EDA_and_Preprocessing/Preprocessing/Preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['three', 'pizzas', 'no', 'american', 'cheese', 'and', 'a', 'water', 'and', 'one', 'ginger', 'ale', 'and', 'a', 'san', 'pellegrino', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']),\n",
       "       list(['three', 'large', 'pizzas', 'with', 'balsamic', 'glaze', 'and', 'three', 'party', 'sized', 'pies', 'with', 'just', 'a', 'little', 'cherry', 'tomato', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']),\n",
       "       list([\"i'd\", 'like', 'a', 'lunch', 'sized', 'pizza', 'with', 'parsley', 'fried', 'onions', 'and', 'parmesan', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']),\n",
       "       list(['two', 'regular', 'pizzas', 'without', 'any', 'caramelized', 'onions', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']),\n",
       "       list([\"i'd\", 'like', 'a', 'pizza', 'with', 'parmesan', 'cheese', 'beef', 'and', 'roasted', 'tomatoes', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_train = pd.read_parquet(PROCESSED_DATA_PATH + '/train_preprocessing.parquet')\n",
    "X_train = np.load(PROCESSED_DATA_PATH + '/X_train.npy', allow_pickle=True)\n",
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Add padding & <UNK> to word2vec model](https://gist.github.com/timotta/ceaec141cbb0b18740b5c48071d989ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T21:16:59.615347Z",
     "iopub.status.busy": "2024-12-06T21:16:59.614501Z",
     "iopub.status.idle": "2024-12-06T21:16:59.673869Z",
     "shell.execute_reply": "2024-12-06T21:16:59.672719Z",
     "shell.execute_reply.started": "2024-12-06T21:16:59.615292Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating '/fast_text_model.bin'...\n"
     ]
    }
   ],
   "source": [
    "model_name = \"/fast_text_model.bin\"\n",
    "update_model = False\n",
    "if update_model or not os.path.exists(MODELS_PATH + model_name):\n",
    "    print(f\"Creating '{model_name}'...\")\n",
    "    # Create a FastText model\n",
    "    EMBED_SIZE = 1024\n",
    "    fast_text_model = FastText(sentences=X_train, vector_size=EMBED_SIZE, window=5, min_count=1, workers=4)\n",
    "    fast_text_model.wv.add_vector(\"<UNK>\", np.zeros(EMBED_SIZE))\n",
    "    fast_text_model.wv[\"<PAD>\"] = np.zeros(EMBED_SIZE)\n",
    "\n",
    "    # Save the trained model\n",
    "    print(f\"Saving '{model_name}'...\")\n",
    "    fast_text_model.save(MODELS_PATH + model_name)\n",
    "else:\n",
    "    print(f\"Loading '{model_name}'...\")\n",
    "    # Load the trained model\n",
    "    fast_text_model = FastText.load(MODELS_PATH + model_name)\n",
    "    \n",
    "fast_text_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-06T21:16:59.675873Z",
     "iopub.status.busy": "2024-12-06T21:16:59.675378Z",
     "iopub.status.idle": "2024-12-06T21:16:59.682666Z",
     "shell.execute_reply": "2024-12-06T21:16:59.681628Z",
     "shell.execute_reply.started": "2024-12-06T21:16:59.675822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_fasttext_embeddings(model_name: str):\n",
    "    print(f\"Loading '{model_name}'...\")\n",
    "    return FastText.load(MODELS_PATH + model_name)\n",
    "\n",
    "def get_word_embedding(fast_text_model, word):\n",
    "    try:\n",
    "        return fast_text_model.wv[word]\n",
    "    except:\n",
    "        return fast_text_model.wv[\"<UNK>\"]\n",
    "    \n",
    "def get_sentence_embedding(fast_text_model, sentence):\n",
    "    return np.array([get_word_embedding(fast_text_model, word) for word in sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading '/word2vec_model.bin'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.7180512 ,  0.00584892,  0.08585259, ..., -1.3326504 ,\n",
       "        -0.3574455 ,  1.9497931 ],\n",
       "       [-0.3477764 , -1.7241757 ,  0.16368103, ..., -0.32398897,\n",
       "        -0.5057439 ,  0.29677933],\n",
       "       [-0.25654992, -0.07621569, -1.0797989 , ..., -0.26241708,\n",
       "         1.1733955 , -0.43284574],\n",
       "       ...,\n",
       "       [ 0.05875031,  0.70974684,  0.297136  , ..., -0.31129286,\n",
       "        -0.2553544 ,  0.5461506 ],\n",
       "       [ 0.05875031,  0.70974684,  0.297136  , ..., -0.31129286,\n",
       "        -0.2553544 ,  0.5461506 ],\n",
       "       [ 0.05875031,  0.70974684,  0.297136  , ..., -0.31129286,\n",
       "        -0.2553544 ,  0.5461506 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model = load_fasttext_embeddings(\"/fast_text_model.bin\")\n",
    "get_sentence_embedding(fast_text_model, X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_embeddings = np.array([get_sentence_embedding(word2vec_model, sentence) for sentence in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118.796875"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_usage()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6200837,
     "sourceId": 10062018,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
